{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas\n",
    "- add population data per country\n",
    "- NOTE: lat/long were added to daily data on march 1st: jan and feb tables only have province/country!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T18:03:08.246514Z",
     "start_time": "2020-03-23T18:03:08.243161Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import chart_studio\n",
    "\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T17:10:46.692345Z",
     "start_time": "2020-03-23T17:10:46.684617Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setting user, api key and access token\n",
    "# The initialization step places a special .plotly/.credentials file in your home directory. \n",
    "# check using:\n",
    "# !cat ~/.plotly/.credentials\n",
    "\n",
    "chart_studio.tools.set_credentials_file(username='jd12006', api_key='GWFstLw9iUHo4yc1DJmq')\n",
    "mapbox_access_token = 'pk.eyJ1IjoiamQxMjAwNiIsImEiOiJjazg0bjdldGQwc2F3M29xdDU2eGo5dnBzIn0.evQ7vR1JE6fVXLNEpmczvA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T17:18:39.613576Z",
     "start_time": "2020-03-23T17:18:39.082715Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"username\": \"jd12006\",\r\n",
      "    \"api_key\": \"GWFstLw9iUHo4yc1DJmq\",\r\n",
      "    \"proxy_username\": \"\",\r\n",
      "    \"proxy_password\": \"\",\r\n",
      "    \"stream_ids\": []\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat ~/.plotly/.credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T17:20:47.101187Z",
     "start_time": "2020-03-23T17:20:47.095729Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set visibility\n",
    "# public: Anyone can view. Private: Only you can view. Secret: anyone with a link can view.\n",
    "chart_studio.tools.set_config_file(world_readable=False, sharing='secret')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: COVID cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series\n",
    "- one file per measure (confirmed dealths, recovered)\n",
    "- one row per province/country\n",
    "- no duplicates from latlongs or multiple entries in same day\n",
    "- dates are columns, with new col added each day and zeros for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T21:51:48.197402Z",
     "start_time": "2020-03-23T21:51:48.168035Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>3/13/20</th>\n",
       "      <th>3/14/20</th>\n",
       "      <th>3/15/20</th>\n",
       "      <th>3/16/20</th>\n",
       "      <th>3/17/20</th>\n",
       "      <th>3/18/20</th>\n",
       "      <th>3/19/20</th>\n",
       "      <th>3/20/20</th>\n",
       "      <th>3/21/20</th>\n",
       "      <th>3/22/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>101.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>138.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1.2833</td>\n",
       "      <td>103.8333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>28.1667</td>\n",
       "      <td>84.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>112.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region      Lat      Long  1/22/20  1/23/20  1/24/20  \\\n",
       "0            NaN       Thailand  15.0000  101.0000        0        0        0   \n",
       "1            NaN          Japan  36.0000  138.0000        0        0        0   \n",
       "2            NaN      Singapore   1.2833  103.8333        0        0        0   \n",
       "3            NaN          Nepal  28.1667   84.2500        0        0        0   \n",
       "4            NaN       Malaysia   2.5000  112.5000        0        0        0   \n",
       "\n",
       "   1/25/20  1/26/20  1/27/20  ...  3/13/20  3/14/20  3/15/20  3/16/20  \\\n",
       "0        0        0        0  ...        1        1        1        1   \n",
       "1        0        0        0  ...       19       22       22       27   \n",
       "2        0        0        0  ...        0        0        0        0   \n",
       "3        0        0        0  ...        0        0        0        0   \n",
       "4        0        0        0  ...        0        0        0        0   \n",
       "\n",
       "   3/17/20  3/18/20  3/19/20  3/20/20  3/21/20  3/22/20  \n",
       "0        1        1        1        1        1        1  \n",
       "1       29       29       29       33       35       40  \n",
       "2        0        0        0        0        2        2  \n",
       "3        0        0        0        0        0        0  \n",
       "4        2        2        2        3        4       10  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.chdir('/Users/jdorni/Documents/training/COVID-19/csse_covid_19_data/csse_covid_19_time_series')\n",
    "# deaths = pd.read_csv('time_series_19-covid-Deaths.csv')\n",
    "# deaths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T21:53:41.599531Z",
     "start_time": "2020-03-23T21:53:41.597336Z"
    }
   },
   "source": [
    "## daily reports\n",
    "- One file per day with latest results from certain countries.\n",
    "- Contains all 3 measures: confirmed, deaths, recovered\n",
    "- Countries dont send updated figures every day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T18:26:24.313927Z",
     "start_time": "2020-03-23T18:26:24.309641Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "['01-22-2020.csv', '01-23-2020.csv', '01-24-2020.csv', '01-25-2020.csv', '01-26-2020.csv', '01-27-2020.csv', '01-28-2020.csv', '01-29-2020.csv', '01-30-2020.csv', '01-31-2020.csv', '02-01-2020.csv', '02-02-2020.csv', '02-03-2020.csv', '02-04-2020.csv', '02-05-2020.csv', '02-06-2020.csv', '02-07-2020.csv', '02-08-2020.csv', '02-09-2020.csv', '02-10-2020.csv', '02-11-2020.csv', '02-12-2020.csv', '02-13-2020.csv', '02-14-2020.csv', '02-15-2020.csv', '02-16-2020.csv', '02-17-2020.csv', '02-18-2020.csv', '02-19-2020.csv', '02-20-2020.csv', '02-21-2020.csv', '02-22-2020.csv', '02-23-2020.csv', '02-24-2020.csv', '02-25-2020.csv', '02-26-2020.csv', '02-27-2020.csv', '02-28-2020.csv', '02-29-2020.csv', '03-01-2020.csv', '03-02-2020.csv', '03-03-2020.csv', '03-04-2020.csv', '03-05-2020.csv', '03-06-2020.csv', '03-07-2020.csv', '03-08-2020.csv', '03-09-2020.csv', '03-10-2020.csv', '03-11-2020.csv', '03-12-2020.csv', '03-13-2020.csv', '03-14-2020.csv', '03-15-2020.csv', '03-16-2020.csv', '03-17-2020.csv', '03-18-2020.csv', '03-19-2020.csv', '03-20-2020.csv', '03-21-2020.csv', '03-22-2020.csv']\n"
     ]
    }
   ],
   "source": [
    "def get_files(path):\n",
    "    \"\"\"\n",
    "    List the csv files in a directory \n",
    "    \"\"\"\n",
    "    files = [x for x in os.listdir(path) if x.endswith(\".csv\")]\n",
    "    return sorted(files)\n",
    "\n",
    "path = '/Users/jdorni/Documents/training/COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "files = get_files(path)\n",
    "print(len(files))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T18:36:02.119347Z",
     "start_time": "2020-03-23T18:36:01.932021Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "02\n",
      "03\n"
     ]
    }
   ],
   "source": [
    "# get all CSVs \n",
    "\n",
    "# NOTE: lat/long were added to daily data on march 1st: jan and feb tables only have province/country!\n",
    "# So need to load months separately\n",
    "\n",
    "\n",
    "file_dict = {}\n",
    "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "path = '/Users/jdorni/Documents/training/COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "\n",
    "for mon in months:\n",
    "    try:\n",
    "        file_path = f'{path}{mon}-*.csv'\n",
    "        file_dict[mon] = pd.concat(map(pd.read_csv, glob.glob(os.path.join('', file_path))))\n",
    "    except Exception as e:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T18:49:23.785447Z",
     "start_time": "2020-03-23T18:49:23.776213Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add NaNs for lat/long in jan/feb \n",
    "# (can join on country and province later if needed?)\n",
    "\n",
    "df_janfeb = pd.concat([file_dict['01'], file_dict['02']]).drop_duplicates()\n",
    "df_janfeb['Latitude'] = np.nan\n",
    "df_janfeb['Longitude'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T18:49:24.663397Z",
     "start_time": "2020-03-23T18:49:24.659226Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_march_onwards = pd.concat([file_dict[k] for k in file_dict.keys() if k not in ['01', '02']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T18:49:38.038702Z",
     "start_time": "2020-03-23T18:49:38.033269Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_janfeb, df_march_onwards])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T18:49:50.870054Z",
     "start_time": "2020-03-23T18:49:50.809629Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 1608 duplicated rows\n",
      "dropped 0 duplicated rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province</th>\n",
       "      <th>country</th>\n",
       "      <th>last update</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>last_updated_ts</th>\n",
       "      <th>last_updated_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hubei</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/31/2020 23:59</td>\n",
       "      <td>5806</td>\n",
       "      <td>204</td>\n",
       "      <td>141</td>\n",
       "      <td>No data</td>\n",
       "      <td>No data</td>\n",
       "      <td>2020-01-31 23:59:00</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zhejiang</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/31/2020 23:59</td>\n",
       "      <td>538</td>\n",
       "      <td>No data</td>\n",
       "      <td>14</td>\n",
       "      <td>No data</td>\n",
       "      <td>No data</td>\n",
       "      <td>2020-01-31 23:59:00</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/31/2020 23:59</td>\n",
       "      <td>436</td>\n",
       "      <td>No data</td>\n",
       "      <td>11</td>\n",
       "      <td>No data</td>\n",
       "      <td>No data</td>\n",
       "      <td>2020-01-31 23:59:00</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Henan</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/31/2020 23:59</td>\n",
       "      <td>352</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>No data</td>\n",
       "      <td>No data</td>\n",
       "      <td>2020-01-31 23:59:00</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hunan</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/31/2020 23:59</td>\n",
       "      <td>332</td>\n",
       "      <td>No data</td>\n",
       "      <td>2</td>\n",
       "      <td>No data</td>\n",
       "      <td>No data</td>\n",
       "      <td>2020-01-31 23:59:00</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    province         country      last update confirmed   deaths recovered  \\\n",
       "0      Hubei  Mainland China  1/31/2020 23:59      5806      204       141   \n",
       "1   Zhejiang  Mainland China  1/31/2020 23:59       538  No data        14   \n",
       "2  Guangdong  Mainland China  1/31/2020 23:59       436  No data        11   \n",
       "3      Henan  Mainland China  1/31/2020 23:59       352        2         3   \n",
       "4      Hunan  Mainland China  1/31/2020 23:59       332  No data         2   \n",
       "\n",
       "  latitude longitude     last_updated_ts last_updated_d  \n",
       "0  No data   No data 2020-01-31 23:59:00     2020-01-31  \n",
       "1  No data   No data 2020-01-31 23:59:00     2020-01-31  \n",
       "2  No data   No data 2020-01-31 23:59:00     2020-01-31  \n",
       "3  No data   No data 2020-01-31 23:59:00     2020-01-31  \n",
       "4  No data   No data 2020-01-31 23:59:00     2020-01-31  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning\n",
    "\n",
    "len0 = len(df)\n",
    "df = df.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "print('dropped', len0 - len(df), 'duplicated rows')\n",
    "\n",
    "# organise cols\n",
    "df.rename({'Country/Region': 'country', 'Province/State': 'province'}, axis=1, inplace=True)\n",
    "df.columns = [x.lower() for x in df.columns]\n",
    "df.fillna('No data', inplace=True)\n",
    "\n",
    "# fix timestamps\n",
    "df['last_updated_ts'] = pd.to_datetime(df[\"last update\"])\n",
    "df['last_updated_d'] = df[\"last_updated_ts\"].dt.date\n",
    "#df.drop('last update', axis=1, inplace=True)\n",
    "#df.drop(['last update', 'last_updated_ts'], axis=1, inplace=True)\n",
    "\n",
    "# check incase 2 updates in a day\n",
    "len0 = len(df)\n",
    "df = df.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "print('dropped', len0 - len(df), 'duplicated rows')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T21:59:19.494677Z",
     "start_time": "2020-03-23T21:59:19.492310Z"
    }
   },
   "source": [
    "###### NOTE DATA NEED FURTHER CLEANING AS THERE ARE DUPLICATES WITHIN DAYS if updated twice in same day, or different date format, missing latlongs etc. But decided to move back to Bokeh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotly\n",
    "\n",
    "Data needs to be dict format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T17:24:34.815826Z",
     "start_time": "2020-03-23T17:24:34.812747Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categories = ['confirmed', 'deaths', 'recovered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make a data dict (IN PROG)\n",
    "\n",
    "data = []\n",
    "for cat in categories:\n",
    "    data = dict(\n",
    "            lat = df.loc[df['EVENT_TYPE'] == event,'BEGIN_LAT'],\n",
    "            lon = df.loc[df['EVENT_TYPE'] == event,'BEGIN_LON'],\n",
    "            name = event,\n",
    "            marker = dict(size = 8, opacity = 0.5),\n",
    "            type = 'scattermapbox'\n",
    "        )\n",
    "    data.append(event_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
